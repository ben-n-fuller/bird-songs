{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook implements multiple signal processing based data transformations to prepare bird song audio data as input to a convolutional neural network classifier. The three methods are the baseline, local energy masking, and global energy masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:06:36.678268: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-06 01:06:36.712208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733447196.730241    5941 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733447196.734981    5941 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 01:06:36.780045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "import math\n",
    "from scipy.io.wavfile import write\n",
    "from scipy.signal import iirfilter, sosfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure GPU is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract\n",
    "In this step we will extract and resample a portion of each observation, saving the resulting signals to a common HDF5 file which we can access later.\n",
    "\n",
    "- Choose a cutoff minimum duration $s$. This will be the common duration for all the samples \n",
    "- Extract the signal and the sample rate for each sample\n",
    "- Average the channels if there are multiple\n",
    "- Truncate to the first $s$ seconds for each sample\n",
    "- Resample to a common rate\n",
    "- Save the signals and the labels to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gen</th>\n",
       "      <th>sp</th>\n",
       "      <th>ssp</th>\n",
       "      <th>group</th>\n",
       "      <th>en</th>\n",
       "      <th>rec</th>\n",
       "      <th>cnt</th>\n",
       "      <th>loc</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>bird-seen</th>\n",
       "      <th>animal-seen</th>\n",
       "      <th>playback-used</th>\n",
       "      <th>temp</th>\n",
       "      <th>regnr</th>\n",
       "      <th>auto</th>\n",
       "      <th>dvc</th>\n",
       "      <th>mic</th>\n",
       "      <th>smp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>936105</td>\n",
       "      <td>Branta</td>\n",
       "      <td>bernicla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birds</td>\n",
       "      <td>Brant Goose</td>\n",
       "      <td>Arjun Dutta</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Great Britain (near  Wallington), Greater Lond...</td>\n",
       "      <td>51.3532</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>Tascam DR-05x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44100</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>934302</td>\n",
       "      <td>Branta</td>\n",
       "      <td>bernicla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birds</td>\n",
       "      <td>Brant Goose</td>\n",
       "      <td>Mats Olsson</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Dalgången 23, Karlshamn, Blekinge län</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>Wildlife Acoustics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24000</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>906056</td>\n",
       "      <td>Branta</td>\n",
       "      <td>bernicla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birds</td>\n",
       "      <td>Brant Goose</td>\n",
       "      <td>Juha Saari</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Pihlajamäki, Helsinki, Uusimaa</td>\n",
       "      <td>60.2357</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telinga PRO-X</td>\n",
       "      <td>44100</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>898133</td>\n",
       "      <td>Branta</td>\n",
       "      <td>bernicla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birds</td>\n",
       "      <td>Brant Goose</td>\n",
       "      <td>Paul Kelly</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Tacumshin Lake (East End), County Wexford</td>\n",
       "      <td>52.1963</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>SM4</td>\n",
       "      <td>SM4</td>\n",
       "      <td>44100</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>882013</td>\n",
       "      <td>Branta</td>\n",
       "      <td>bernicla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>birds</td>\n",
       "      <td>Brant Goose</td>\n",
       "      <td>Jean COURTIN</td>\n",
       "      <td>France</td>\n",
       "      <td>Arrondissement de Vannes (near  Sérent), Morbi...</td>\n",
       "      <td>47.7981</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44100</td>\n",
       "      <td>goose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     gen        sp  ssp  group           en           rec  \\\n",
       "0  936105  Branta  bernicla  NaN  birds  Brant Goose   Arjun Dutta   \n",
       "1  934302  Branta  bernicla  NaN  birds  Brant Goose   Mats Olsson   \n",
       "2  906056  Branta  bernicla  NaN  birds  Brant Goose    Juha Saari   \n",
       "3  898133  Branta  bernicla  NaN  birds  Brant Goose    Paul Kelly   \n",
       "4  882013  Branta  bernicla  NaN  birds  Brant Goose  Jean COURTIN   \n",
       "\n",
       "              cnt                                                loc      lat  \\\n",
       "0  United Kingdom  Great Britain (near  Wallington), Greater Lond...  51.3532   \n",
       "1          Sweden              Dalgången 23, Karlshamn, Blekinge län      NaN   \n",
       "2         Finland                     Pihlajamäki, Helsinki, Uusimaa  60.2357   \n",
       "3         Ireland          Tacumshin Lake (East End), County Wexford  52.1963   \n",
       "4          France  Arrondissement de Vannes (near  Sérent), Morbi...  47.7981   \n",
       "\n",
       "   ...  bird-seen animal-seen playback-used temp regnr auto  \\\n",
       "0  ...         no          no            no  NaN   NaN   no   \n",
       "1  ...         no          no            no  NaN   NaN   no   \n",
       "2  ...         no          no            no  NaN   NaN  yes   \n",
       "3  ...         no          no            no  NaN   NaN  yes   \n",
       "4  ...        yes         yes            no  NaN   NaN  yes   \n",
       "\n",
       "                  dvc            mic    smp  label  \n",
       "0       Tascam DR-05x            NaN  44100  goose  \n",
       "1  Wildlife Acoustics            NaN  24000  goose  \n",
       "2                 NaN  Telinga PRO-X  44100  goose  \n",
       "3                 SM4           SM4   44100  goose  \n",
       "4                 NaN            NaN  44100  goose  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract metadata\n",
    "metadata = pd.read_csv('/data/recordings.csv')\n",
    "metadata['length'] = metadata['length'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_middle(signal, fs, duration_seconds=10):\n",
    "    duration_samples = duration_seconds * fs\n",
    "    signal_length = len(signal)\n",
    "    start = (signal_length - duration_samples) // 2\n",
    "    end = start + duration_samples\n",
    "    return signal[start:end]\n",
    "\n",
    "def extract_beginning(signal, fs, duration_seconds=10):\n",
    "    duration_samples = duration_seconds * fs\n",
    "    return signal[0:duration_samples]\n",
    "\n",
    "def make_label_dict(metadata):\n",
    "    return {label: i for i, label in enumerate(metadata['label'].unique())}\n",
    "\n",
    "def load_batch(batch, label_dict, duration_seconds=10, target_fs=16000, extract_fn=extract_middle):\n",
    "    signals = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i, file in enumerate(batch):\n",
    "        # Check that file exists\n",
    "        if not os.path.exists(f'/data/recordings/{file}'):\n",
    "            print(f'Skipping {file} due to missing file')\n",
    "            continue\n",
    "        # Load\n",
    "        signal, fs = librosa.load(f'/data/recordings/{file}', sr=None, mono=False)\n",
    "\n",
    "        # Check for multiple channels\n",
    "        if signal.ndim > 1:\n",
    "            signal = np.mean(signal, axis=0)\n",
    "\n",
    "        # Extract signal of common duration\n",
    "        signal = extract_fn(signal, fs, duration_seconds)\n",
    "        if len(signal) != duration_seconds * fs:\n",
    "            print(f'Skipping {file} due to incorrect duration')\n",
    "            continue\n",
    "\n",
    "        # Resample\n",
    "        signal = librosa.resample(signal, orig_sr=fs, target_sr=target_fs)\n",
    "\n",
    "        # Add to batch\n",
    "        signals.append(signal)\n",
    "\n",
    "        # Extract label\n",
    "        file_name = file.split('_')\n",
    "        labels.append(label_dict[file_name[0]])\n",
    "        ids.append(int(file_name[1].split('.')[0]))\n",
    "\n",
    "    return np.array(signals), np.array(ids), np.array(labels)\n",
    "\n",
    "def save_batch(batch, save_path, dataset_name='signals'):\n",
    "    with h5py.File(save_path, 'a') as f:\n",
    "        if dataset_name in f:\n",
    "            dataset = f[dataset_name]\n",
    "            dataset.resize(dataset.shape[0] + batch.shape[0], axis=0)\n",
    "            dataset[-batch.shape[0]:] = batch\n",
    "        else:\n",
    "            maxshape = (None,) + batch.shape[1:]\n",
    "            f.create_dataset(dataset_name, data=batch, maxshape=maxshape, chunks=True)\n",
    "\n",
    "def get_batches(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i + batch_size]\n",
    "\n",
    "def extract_signals(file_list, save_path, label_dict, duration_seconds=10, batch_size=32, target_fs=16000, extract_fn=extract_middle):\n",
    "    for i, batch_files in enumerate(get_batches(file_list, batch_size)):\n",
    "        signals, ids, labels = load_batch(batch_files, label_dict, duration_seconds, target_fs, extract_fn)\n",
    "        save_batch(signals, save_path, f'signals_{duration_seconds}s_{target_fs}hz')\n",
    "        save_batch(labels, save_path, 'labels')\n",
    "        save_batch(ids, save_path, 'ids')\n",
    "        print(f'Saved {len(batch_files)} signals for batch {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = make_label_dict(metadata)\n",
    "files = os.listdir('/data/recordings')\n",
    "output_path = '/data/signals.h5'\n",
    "\n",
    "if extract:\n",
    "    extract_signals(files, output_path, label_dict, duration_seconds=10, batch_size=64, target_fs=16000, extract_fn=extract_beginning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "- Framing\n",
    "- Windowing (using a Hamming function)\n",
    "- Low-pass filter\n",
    "- FFT (real-valued) to produce the spectrogram\n",
    "- Take the log magnitude of the spectrum\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(signal, cutoff=6250, order=8, fs=16000):\n",
    "    # Design\n",
    "    sos = iirfilter(\n",
    "        N=order,\n",
    "        Wn=cutoff / (fs / 2),\n",
    "        btype='low', \n",
    "        ftype='butter',\n",
    "        output='sos'\n",
    "    )\n",
    "    \n",
    "    # Apply\n",
    "    filtered_signal = sosfilt(sos, signal)\n",
    "    \n",
    "    return tf.convert_to_tensor(filtered_signal, dtype=tf.float32)\n",
    "\n",
    "def tf_low_pass_filter(signal, fs=16000, filter_order=8, filter_cutoff=6250):\n",
    "    result = tf.numpy_function(\n",
    "        func= lambda signals: low_pass_filter(signals, cutoff=filter_cutoff, order=filter_order, fs=fs), \n",
    "        inp=[signal], \n",
    "        Tout=tf.float32\n",
    "    )\n",
    "    result.set_shape(signal.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_window_fft_log_dataset(dataset, frame_size = 1024, step_size = 512, fs=16000, filter_order=8, filter_cutoff=6250):\n",
    "    window = tf.signal.hamming_window(frame_size)\n",
    "    \n",
    "    # Framing\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf.signal.frame(signals, frame_size, step_size), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Windowing\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (signals * window, labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Apply filter\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf_low_pass_filter(signals, fs, filter_order, filter_cutoff), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Real-valued Fourier Transform\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf.abs(tf.signal.rfft(signals)), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Log-magnitude\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf.math.log(signals + 1e-6), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Energy Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_signals_local(ft, threshold=0.2):\n",
    "    # Create mask\n",
    "    row_means, row_vars = tf.nn.moments(ft, axes=[2])\n",
    "    mask = tf.add(row_means, threshold * row_vars)\n",
    "    mask_expanded = tf.expand_dims(mask, axis=-1)  # Shape (n, N, 1)\n",
    "\n",
    "    # Broadcast the mask to the same shape as the spectrograms\n",
    "    mask_expanded = tf.broadcast_to(mask_expanded, tf.shape(ft))  # Shape (n, N, K)\n",
    "\n",
    "    # Apply mask\n",
    "    ft_masked = tf.where(ft < mask_expanded, tf.zeros_like(ft), ft)\n",
    "    return ft_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_local_masking_dataset(dataset, threshold=0.2):\n",
    "    # Apply mask\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (mask_signals_local(signals, threshold), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Energy Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_signals_global(ft, threshold = 0.2, cell_height=32, cell_width=32):\n",
    "        # We need to reshape each sample into smaller cells\n",
    "    # The size may not be consistent so we need padding\n",
    "    N, K = tf.shape(ft).numpy()[1:]\n",
    "    pad_N = (cell_height - (N % cell_height)) % cell_height\n",
    "    pad_K = (cell_width - (K % cell_width)) % cell_width\n",
    "    padding = [[0, 0], [0, pad_N], [0, pad_K]]\n",
    "    ft_padded = tf.pad(ft, padding)\n",
    "\n",
    "    # New dimensions after padding\n",
    "    new_N = N + pad_N\n",
    "    new_K = K + pad_K\n",
    "\n",
    "    # Reshape to create cells\n",
    "    n_cells = new_N // cell_height\n",
    "    k_cells = new_K // cell_width\n",
    "\n",
    "    # Reshape tensor into cells of size (n, n_cells, k_cells, cell_height, cell_width)\n",
    "    cells = tf.reshape(ft_padded, (num_samples, n_cells, cell_height, k_cells, cell_width))\n",
    "\n",
    "    # Compute global mean and variance\n",
    "    global_mean, global_variance = tf.nn.moments(ft, axes=[1, 2])\n",
    "    global_mask = global_mean + threshold * tf.sqrt(global_variance)\n",
    "\n",
    "    # Compute means of each cell\n",
    "    cell_means = tf.reduce_mean(cells, axis=[2, 4])\n",
    "\n",
    "    # Expand the global mask to the shape of cell means\n",
    "    global_mask_expanded = tf.reshape(global_mask, (num_samples, 1, 1))\n",
    "    global_mask_expanded = tf.broadcast_to(global_mask_expanded, tf.shape(cell_means))\n",
    "\n",
    "    # # Filter cells based on the global mask\n",
    "    filtered_cell_means = tf.where(cell_means < global_mask_expanded, tf.zeros_like(cell_means), cell_means)\n",
    "\n",
    "    # Expand filtered cell means back to the shape of padded tensor\n",
    "    filtered_cells_expanded = tf.reshape(filtered_cell_means, (num_samples, n_cells, 1, k_cells, 1))\n",
    "    filtered_cells_expanded = tf.broadcast_to(filtered_cells_expanded, tf.shape(cells))\n",
    "\n",
    "    # # Apply the filtered cell means to the original cells\n",
    "    filtered_cells = tf.where(filtered_cells_expanded == 0, tf.zeros_like(cells), cells)\n",
    "\n",
    "    # # Reshape back to the original padded shape (n, new_N, new_K)\n",
    "    padded_result = tf.reshape(filtered_cells, (num_samples, new_N, new_K))\n",
    "\n",
    "    # # Optionally: Remove the padding to restore the original dimensions\n",
    "    final_result = padded_result[:, :N, :K]\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_global_masking_dataset(dataset, threshold=0.2, cell_height=32, cell_width=32):\n",
    "    # Apply mask\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (mask_signals_global(signals, threshold, cell_height, cell_width), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, num_labels=3):\n",
    "    # Normalization\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf.math.divide(signals, tf.reduce_max(signals)), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # OHE\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (signals, tf.one_hot(labels, depth=num_labels)),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda signals, labels: (tf.expand_dims(signals, axis=-1), labels),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the signals\n",
    "with h5py.File('/data/signals.h5', 'r') as f:\n",
    "    signals = f['signals_10s_16000hz'][:]\n",
    "    labels = f['labels'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as wav files\n",
    "# if extract:\n",
    "# for i, (signal, label) in enumerate(zip(signals, labels)):\n",
    "#     write(f'/data/short-recordings/{i}_{label}.wav', 16000, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(signals, labels):\n",
    "    signal_dataset = tf.data.Dataset.from_tensor_slices(signals)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((signal_dataset, label_dataset))\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=32)\n",
    "    return dataset\n",
    "\n",
    "def create_baseline_dataset(dataset, frame_size = 1024, step_size = 512, fs=16000, filter_order=8, filter_cutoff=6250, batch_size=64, num_labels=3):\n",
    "    dataset = frame_window_fft_log_dataset(dataset, frame_size, step_size, fs, filter_order, filter_cutoff)\n",
    "    dataset = normalize_dataset(dataset, num_labels=num_labels)\n",
    "    return dataset\n",
    "\n",
    "def create_local_masking_dataset(dataset, frame_size = 1024, step_size = 512, fs=16000, filter_order=8, filter_cutoff=6250, threshold=0.2, batch_size=64, num_labels=3):\n",
    "    dataset = frame_window_fft_log_dataset(dataset, frame_size, step_size, fs, filter_order, filter_cutoff)\n",
    "    dataset = apply_local_masking_dataset(dataset, threshold)\n",
    "    dataset = normalize_dataset(dataset, num_labels=num_labels)\n",
    "    return dataset\n",
    "\n",
    "def create_global_masking_dataset(dataset, frame_size = 1024, step_size = 512, fs=16000, filter_order=8, filter_cutoff=6250, threshold=0.2, cell_height=32, cell_width=32):\n",
    "    dataset = frame_window_fft_log_dataset(dataset, frame_size, step_size, fs, filter_order, filter_cutoff)\n",
    "    dataset = apply_global_masking_dataset(dataset, threshold)\n",
    "    dataset = normalize_dataset(dataset, num_labels=num_labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.7\n",
    "val_frac = 0.1\n",
    "test_frac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "frame_size = int(0.05 * sample_rate)\n",
    "step_size = frame_size // 4\n",
    "filter_order = 8\n",
    "filter_cutoff = 6250\n",
    "threshold = 0.2\n",
    "cell_height = 32\n",
    "cell_width = 32\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(signals, labels, train_frac=0.7, val_frac=0.1, test_frac=0.2):\n",
    "    # Shuffle\n",
    "    indices = np.arange(len(signals))\n",
    "    np.random.shuffle(indices)\n",
    "    signals = signals[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Split\n",
    "    train_idx = int(train_frac * len(signals))\n",
    "    val_idx = int((train_frac + val_frac) * len(signals))\n",
    "\n",
    "    train_signals = signals[:train_idx]\n",
    "    val_signals = signals[train_idx:val_idx]\n",
    "    test_signals = signals[val_idx:]\n",
    "\n",
    "    train_labels = labels[:train_idx]\n",
    "    val_labels = labels[train_idx:val_idx]\n",
    "    test_labels = labels[val_idx:]\n",
    "\n",
    "    return train_signals, val_signals, test_signals, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signals, val_signals, test_signals, train_labels, val_labels, test_labels = train_test_val_split(signals, labels, train_frac, val_frac, test_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733447296.420195    5941 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset(train_signals, train_labels)\n",
    "val_dataset = create_dataset(val_signals, val_labels)\n",
    "# test_dataset = create_dataset(test_signals, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_train_dataset = create_baseline_dataset(train_dataset, frame_size, step_size, sample_rate, filter_order, filter_cutoff, batch_size, 3)\n",
    "# baseline_val_dataset = create_baseline_dataset(val_dataset, frame_size, step_size, sample_rate, filter_order, filter_cutoff, batch_size, 3)\n",
    "# baseline_test_dataset = create_baseline_dataset(test_dataset, frame_size, step_size, sample_rate, filter_order, filter_cutoff, batch_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_masking_dataset = create_local_masking_dataset(dataset, frame_size, step_size, sample_rate, filter_order, filter_cutoff, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_masking_dataset = create_global_masking_dataset(dataset, frame_size, step_size, sample_rate, filter_order, filter_cutoff, threshold, cell_height, cell_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrograms(spectrograms, labels, title, save=False):\n",
    "    fig, axs = plt.subplots(8, 4, figsize=(24, 16))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(tf.transpose(spectrograms[i, :, :]))\n",
    "        ax.set_title(f'Signal {i} - {labels[i]}')\n",
    "        \n",
    "        # Turn of axis labels\n",
    "        ax.axis('off')\n",
    "    if save:\n",
    "        plt.savefig(f'/data/spectrograms/{title}.png')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_spectrogram(spectrogram, title, save=False):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.flip(tf.transpose(spectrogram), axis=0))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(f'/data/spectrograms/{title}.png')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_batch, label_batch = next(iter(baseline_train_dataset))\n",
    "# signal_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_spectrograms(signal_batch, label_batch, 'Baseline Spectrograms', save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        # layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_input_size(sample_rate, duration_seconds, frame_size, step_size):\n",
    "    signal_length = sample_rate * duration_seconds\n",
    "    \n",
    "    # Compute the number of frames\n",
    "    num_frames = math.floor((signal_length - frame_size) / step_size) + 1\n",
    "    \n",
    "    # Compute the number of frequency bins\n",
    "    frequency_bins = frame_size // 2 + 1\n",
    "    \n",
    "    return num_frames, frequency_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(797, 401)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames, freq_bins = compute_input_size(sample_rate, 10, frame_size, step_size)\n",
    "num_frames, freq_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model((num_frames, freq_bins, 1), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(baseline_train_dataset, batch_size=batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
